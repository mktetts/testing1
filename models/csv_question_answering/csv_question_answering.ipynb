{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Skipping openvino as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q --upgrade pip\n",
    "# this model is not supported in release, so we have to install nightly version\n",
    "%pip uninstall -q -y openvino\n",
    "%pip install -q openvino-nightly\n",
    "# other dependencies\n",
    "%pip install -q torch \"transformers>=4.31.0\"\n",
    "%pip install -q \"gradio>=4.0.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 22:54:53.482929: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-09 22:54:54.278161: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-09 22:54:54.278398: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-09 22:54:54.281381: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-09 22:54:54.612232: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 22:54:56.905683: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import TapasForQuestionAnswering\n",
    "from transformers import TapasTokenizer\n",
    "from transformers import pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from io import StringIO\n",
    "# import requests\n",
    "# cid = 'QmRTR2xVuxbVZ2umscMraQp4UsUwuCS2VHeJZNTKSi5zKL'\n",
    "# ipfs_gateway_url = f'https://ipfs.io/ipfs/{cid}'\n",
    "# response = requests.get(ipfs_gateway_url)\n",
    "# csv_content = response.text\n",
    "# table = pd.read_csv(StringIO(csv_content))\n",
    "# print(table)\n",
    "\n",
    "\n",
    "\n",
    "model = TapasForQuestionAnswering.from_pretrained('google/tapas-large-finetuned-wtq')\n",
    "tokenizer = TapasTokenizer.from_pretrained(\"google/tapas-large-finetuned-wtq\")\n",
    "table = pd.read_csv('../dataset/symptom_and_medicine.csv', delimiter=\",\")\n",
    "table = table.astype(str)\n",
    "question = \"medicine for fever and nausea?\"\n",
    "# print(table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is  Paracetamol\n"
     ]
    }
   ],
   "source": [
    "tqa = pipeline(task=\"table-question-answering\", model=model, tokenizer=tokenizer)\n",
    "result = tqa(table=table, query=question)\n",
    "print(f\"The answer is {result['cells'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import openvino as ov\n",
    "\n",
    "\n",
    "# Define the input shape\n",
    "batch_size = 1\n",
    "sequence_length = 29\n",
    "\n",
    "# Modify the input shape of the dummy_input dictionary\n",
    "dummy_input = {\n",
    "    \"input_ids\": torch.zeros((batch_size, sequence_length), dtype=torch.long),\n",
    "    \"attention_mask\": torch.zeros((batch_size, sequence_length), dtype=torch.long),\n",
    "    \"token_type_ids\": torch.zeros((batch_size, sequence_length, 7), dtype=torch.long),\n",
    "}\n",
    "\n",
    "\n",
    "ov_model_xml_path = Path('../../python_backend/trained_models/question_answering/qa.xml')\n",
    "\n",
    "if not ov_model_xml_path.exists():\n",
    "    ov_model = ov.convert_model(\n",
    "        model,\n",
    "        example_input=dummy_input\n",
    "    )\n",
    "    ov.save_model(ov_model, ov_model_xml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e033d01ae644e8be0c167fa6982ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Device:', index=1, options=('CPU', 'AUTO'), value='AUTO')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "core = ov.Core()\n",
    "\n",
    "device = widgets.Dropdown(\n",
    "    options=core.available_devices + [\"AUTO\"],\n",
    "    value='AUTO',\n",
    "    description='Device:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "inputs = tokenizer(table=table, queries=question, padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "compiled_model = core.compile_model(ov_model_xml_path, device.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = compiled_model((inputs[\"input_ids\"], inputs[\"attention_mask\"], inputs[\"token_type_ids\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Paracetamol\n"
     ]
    }
   ],
   "source": [
    "logits = result[0]\n",
    "logits_aggregation = result[1]\n",
    "\n",
    "\n",
    "predictions = tokenizer.convert_logits_to_predictions(inputs, torch.from_numpy(result[0]))\n",
    "answer_coordinates_batch = predictions[0]\n",
    "aggregators = {}\n",
    "aggregators_prefix = {}\n",
    "answers = []\n",
    "for index, coordinates in enumerate(answer_coordinates_batch):\n",
    "    cells = [table.iat[coordinate] for coordinate in coordinates]\n",
    "    aggregator = aggregators.get(index, \"\")\n",
    "    aggregator_prefix = aggregators_prefix.get(index, \"\")\n",
    "    answer = {\n",
    "        \"answer\": aggregator_prefix + \", \".join(cells),\n",
    "        \"coordinates\": coordinates,\n",
    "        \"cells\": [table.iat[coordinate] for coordinate in coordinates],\n",
    "    }\n",
    "    if aggregator:\n",
    "        answer[\"aggregator\"] = aggregator\n",
    "\n",
    "    answers.append(answer)\n",
    "\n",
    "print(answers[0][\"cells\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import TapasConfig\n",
    "\n",
    "\n",
    "# # get config for pretrained model\n",
    "# config = TapasConfig.from_pretrained('google/tapas-large-finetuned-wtq')\n",
    "\n",
    "\n",
    "\n",
    "# class TapasForQuestionAnswering(TapasForQuestionAnswering):  # it is better to keep the class name to avoid warnings\n",
    "#     def __init__(self, ov_model_path):\n",
    "#         super().__init__(config)  # pass config from the pretrained model\n",
    "#         self.tqa_model = core.compile_model(ov_model_path, device.value)\n",
    "\n",
    "#     def forward(self, input_ids, *, attention_mask, token_type_ids):\n",
    "#         results = self.tqa_model((input_ids, attention_mask, token_type_ids))\n",
    "\n",
    "#         return torch.from_numpy(results[0]), torch.from_numpy(results[1])\n",
    "\n",
    "\n",
    "# compiled_model = TapasForQuestionAnswering(ov_model_xml_path)\n",
    "# tqa = pipeline(task=\"table-question-answering\", model=compiled_model, tokenizer=tokenizer)\n",
    "\n",
    "# print(tqa(table=table, query=question)[\"cells\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
